{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Loading flights data per month from csv into dataframe\n",
    "# Data from https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236\n",
    "# Data provided in per month blocks, selected month blocks were filtered by \n",
    "# 'Washington' i.e. all flights that arrived or departed from airports that\n",
    "# were in the database that were in Washington. Nov. 2018 is the latest flight\n",
    "# data released.\n",
    "dec_2017_df = pd.read_csv('data-raw/dec_2017_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "jan_2018_df = pd.read_csv('data-raw/jan_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "feb_2018_df = pd.read_csv('data-raw/feb_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "mar_2018_df = pd.read_csv('data-raw/mar_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "apr_2018_df = pd.read_csv('data-raw/apr_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "may_2018_df = pd.read_csv('data-raw/may_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "jun_2018_df = pd.read_csv('data-raw/jun_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "jul_2018_df = pd.read_csv('data-raw/jul_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "aug_2018_df = pd.read_csv('data-raw/aug_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "sep_2018_df = pd.read_csv('data-raw/sep_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "oct_2018_df = pd.read_csv('data-raw/oct_2018_T_ONTIME_REPORTING.csv', index_col=False)\n",
    "nov_2018_df = pd.read_csv('data-raw/nov_2018_T_ONTIME_REPORTING.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining separate month dataframes into one year long data frame\n",
    "flights = pd.concat([dec_2017_df, jan_2018_df, feb_2018_df, mar_2018_df, \n",
    "                     apr_2018_df, may_2018_df, jun_2018_df, jul_2018_df,\n",
    "                     aug_2018_df, sep_2018_df, oct_2018_df, nov_2018_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data-raw/weather_2018.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ed847b428138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load in weather data from https://www.ncdc.noaa.gov/cdo-web/datatools/lcd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mweather_2018\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data-raw/weather_2018.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# data for all of 2018\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mweather_dec_2017\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data-raw/weather_dec_2017.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# data for December 2017\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Combine into one dataframe for weather for Dec 2017 - November 2018\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'data-raw/weather_2018.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Load in weather data from https://www.ncdc.noaa.gov/cdo-web/datatools/lcd\n",
    "weather_2018 = pd.read_csv('data-raw/weather_2018.csv', index_col=False) # data for all of 2018\n",
    "weather_dec_2017 = pd.read_csv('data-raw/weather_dec_2017.csv', index_col=False) # data for December 2017\n",
    "\n",
    "# Combine into one dataframe for weather for Dec 2017 - November 2018\n",
    "weather = pd.concat([weather_dec_2017, weather_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR                       int64\n",
      "QUARTER                    int64\n",
      "MONTH                      int64\n",
      "DAY_OF_MONTH               int64\n",
      "DAY_OF_WEEK                int64\n",
      "FL_DATE                   object\n",
      "OP_UNIQUE_CARRIER         object\n",
      "ORIGIN_AIRPORT_ID          int64\n",
      "ORIGIN_AIRPORT_SEQ_ID      int64\n",
      "ORIGIN_CITY_MARKET_ID      int64\n",
      "ORIGIN                    object\n",
      "ORIGIN_CITY_NAME          object\n",
      "DEST_AIRPORT_ID            int64\n",
      "DEST_AIRPORT_SEQ_ID        int64\n",
      "DEST_CITY_MARKET_ID        int64\n",
      "DEST                      object\n",
      "DEST_CITY_NAME            object\n",
      "CRS_DEP_TIME               int64\n",
      "DEP_TIME                 float64\n",
      "DEP_DELAY                float64\n",
      "DEP_DELAY_NEW            float64\n",
      "DEP_DEL15                float64\n",
      "CANCELLED                float64\n",
      "DIVERTED                 float64\n",
      "AIR_TIME                 float64\n",
      "DISTANCE                 float64\n",
      "CARRIER_DELAY            float64\n",
      "WEATHER_DELAY            float64\n",
      "NAS_DELAY                float64\n",
      "SECURITY_DELAY           float64\n",
      "LATE_AIRCRAFT_DELAY      float64\n",
      "Unnamed: 31              float64\n",
      "dtype: object\n",
      "Index(['YEAR', 'QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'FL_DATE',\n",
      "       'OP_UNIQUE_CARRIER', 'ORIGIN_AIRPORT_ID', 'ORIGIN_AIRPORT_SEQ_ID',\n",
      "       'ORIGIN_CITY_MARKET_ID', 'ORIGIN', 'ORIGIN_CITY_NAME',\n",
      "       'DEST_AIRPORT_ID', 'DEST_AIRPORT_SEQ_ID', 'DEST_CITY_MARKET_ID', 'DEST',\n",
      "       'DEST_CITY_NAME', 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY',\n",
      "       'DEP_DELAY_NEW', 'DEP_DEL15', 'CANCELLED', 'DIVERTED', 'AIR_TIME',\n",
      "       'DISTANCE', 'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY',\n",
      "       'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check column data types\n",
    "print(flights.dtypes)\n",
    "\n",
    "# I notice a column that wasn't described as in the dataset on the BTS website so I drop it\n",
    "flights = flights.drop('Unnamed: 31', axis = 1)\n",
    "\n",
    "# Double check it's dropped\n",
    "print(flights.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find flights only leaving SeaTac\n",
    "flights = flights[flights.ORIGIN == 'SEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15       2017120122\n",
       "16       2017120222\n",
       "17       2017120322\n",
       "18       2017120422\n",
       "19       2017120522\n",
       "20       2017120622\n",
       "21       2017120722\n",
       "22       2017120822\n",
       "23       2017120922\n",
       "24       2017121022\n",
       "25       2017121122\n",
       "26       2017121222\n",
       "27       2017121322\n",
       "28       2017121422\n",
       "29       2017121522\n",
       "30       2017121622\n",
       "31       2017121722\n",
       "32       2017121822\n",
       "33       2017121922\n",
       "34       2017122022\n",
       "35       2017122122\n",
       "36       2017122222\n",
       "37       2017122322\n",
       "38       2017122422\n",
       "39       2017122522\n",
       "40       2017122622\n",
       "41       2017122722\n",
       "42       2017122822\n",
       "43       2017122922\n",
       "44       2017123022\n",
       "            ...    \n",
       "23434    2018110823\n",
       "23436    2018110809\n",
       "23437    2018110815\n",
       "23439    2018110806\n",
       "23440    2018110812\n",
       "23442    2018110819\n",
       "23446    2018110823\n",
       "23448    2018110805\n",
       "23449    2018110800\n",
       "23450    2018110811\n",
       "23451    2018110822\n",
       "23454    2018110813\n",
       "23456    2018110813\n",
       "23458    2018110811\n",
       "23459    2018110809\n",
       "23461    2018110814\n",
       "23462    2018110805\n",
       "23465    2018110823\n",
       "23469    2018110817\n",
       "23472    2018110806\n",
       "23474    2018110807\n",
       "23476    2018110808\n",
       "23480    2018110817\n",
       "23482    2018110807\n",
       "23484    2018110814\n",
       "23485    2018110810\n",
       "23487    2018110813\n",
       "23489    2018110818\n",
       "23496    2018110723\n",
       "23498    2018110709\n",
       "Name: join_time, Length: 140320, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new series that represents the hour a flight happened in\n",
    "dep_times = flights.CRS_DEP_TIME.apply(str)\n",
    "hours = []\n",
    "for time in dep_times:\n",
    "    if len(time) == 1 or len(time) == 2:\n",
    "        hours.append('00')\n",
    "    elif len(time) == 3:\n",
    "        hours.append('0' + time[0])\n",
    "    else:\n",
    "        hours.append(time[:2])\n",
    "\n",
    "# Create new series for day of month in dd format\n",
    "day_of_month = flights.DAY_OF_MONTH.apply(str)\n",
    "days = []\n",
    "for day in day_of_month:\n",
    "    if len(day) == 1:\n",
    "        days.append('0' + day)\n",
    "    else:\n",
    "        days.append(day)\n",
    "\n",
    "# Create new series for month in mm format\n",
    "month = flights.MONTH.apply(str)\n",
    "months = []\n",
    "for m in month:\n",
    "    if len(m) == 1:\n",
    "        months.append('0' + m)\n",
    "    else:\n",
    "        months.append(m)\n",
    "\n",
    "# Create new variable in format yyyymmddhh to allow join with weather data\n",
    "flights['join_time'] = flights.YEAR.apply(str) + months + days + hours\n",
    "\n",
    "# Change 'join_time' type to int64\n",
    "flights.join_time.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the join_time value for each hour\n",
    "join_time = list(flights.groupby('join_time').groups.keys())\n",
    "\n",
    "# Compute the average flight delay for each join_time hour\n",
    "avg_delay = flights.groupby('join_time')['DEP_DELAY'].aggregate('mean')\n",
    "\n",
    "# Compute the average flight delay for each join_time hour the data says was caused by weather\n",
    "actual_weather_delay = flights.groupby('join_time')['WEATHER_DELAY'].aggregate('mean')\n",
    "\n",
    "# Create a dataframe with the join_time and avg_delay\n",
    "flight_delays = pd.DataFrame({'join_time':join_time,\n",
    "                              'avg_delay':list(avg_delay),\n",
    "                              'actual_weather_delay': list(actual_weather_delay)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .csv to use to combine with weather data\n",
    "flight_delays.to_csv('data/hourly_avg_flight_delays.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
